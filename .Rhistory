date.months<-as.Date(dat$date.months)
dat %>%
group_by(Article.Type, date.months, Tone) %>%
filter(Article.Type!='Editorial') %>%
summarize(value=sum(Tone))
dat %>%
group_by(Article.Type, date.months, Tone) %>%
filter(Article.Type!='Editorial') %>%
summarize(value=sum(Tone))%>%
ggplot(aes(y=value, x=date.months))+geom_bar(stat='identity')+facet_grid(Article.Type~Overall.Tone.Argument)+labs(x='Date, by Months', y='Frequency', title='Fluoridation Articles By Type And Tone')
dat %>%
group_by(Article.Type, date.months, Tone) %>%
filter(Article.Type!='Editorial') %>%
summarize(value=sum(Tone))%>%
ggplot(aes(y=value, x=date.months))+geom_bar(stat='identity')+facet_grid(Article.Type~tone)+labs(x='Date, by Months', y='Frequency', title='Fluoridation Articles By Type And Tone')
dat %>%
group_by(Article.Type, date.months, Tone) %>%
filter(Article.Type!='Editorial') %>%
summarize(value=sum(Tone))%>%
ggplot(aes(y=value, x=date.months))+geom_bar(stat='identity')+facet_grid(Article.Type~Tone)+labs(x='Date, by Months', y='Frequency', title='Fluoridation Articles By Type And Tone')
dat$Tone<-recode(dat$Overall.Tone.Argument, as.factor.result=TRUE,"1='Pro-fluoridation'; 2='Neutral'; 3='Con-fluoridation'", levels=c('Pro-fluoridation', 'Neutral', 'Con-fluoridation'))
tone_table<-table(dat$Tone)
#Join with article type
article_tone_table<-cbind(rownames(article_type),article_type, rownames(tone_table), tone_table)
#Write out article type and tone for descriptives
write.table(article_tone_table, file='article_tone_table.csv', row.names=FALSE, sep=',')
#Turn Date into date class
date.months<-as.Date(dat$date.months)
dat %>%
group_by(Article.Type, date.months, Tone) %>%
filter(Article.Type!='Editorial') %>%
summarize(value=sum(Tone))%>%
ggplot(aes(y=value, x=date.months))+geom_bar(stat='identity')+facet_grid(Article.Type~Tone)+labs(x='Date, by Months', y='Frequency', title='Fluoridation Articles By Type And Tone')
dat %>%
group_by(Article.Type, date.months, Tone) %>%
filter(Article.Type!='Editorial') %>%
summarize(value=sum(Tone))%>%
ggplot(aes(y=value, x=date.months))+geom_bar(stat='identity')+facet_grid(Article.Type~Tone)+labs(x='Date, by Months', y='Frequency', title='Fluoridation Articles By Type And Tone')+theme(axis.text.x = element_text(angle = 45, hjust = 1))
?element_text
dat %>%
group_by(Article.Type, date.months, Tone) %>%
filter(Article.Type!='Editorial') %>%
summarize(value=sum(Tone))%>%
ggplot(aes(y=value, x=date.months))+geom_bar(stat='identity')+facet_grid(Article.Type~Tone)+labs(x='Date, by Months', y='Frequency', title='Fluoridation Articles By Type And Tone')+theme(axis.text.x = element_text(angle = 45, hjust = 1, size=0.75))
dat %>%
group_by(Article.Type, date.months, Tone) %>%
filter(Article.Type!='Editorial') %>%
summarize(value=sum(Tone))%>%
ggplot(aes(y=value, x=date.months))+geom_bar(stat='identity')+facet_grid(Article.Type~Tone)+labs(x='Date, by Months', y='Frequency', title='Fluoridation Articles By Type And Tone')+theme(axis.text.x = element_text(angle = 45, hjust = 1, size=6))
Sys.setenv(NOAWT=TRUE)
to.install<-c('tm', 'car', 'tm.plugin.waterloo', 'SnowballC', 'RWeka', 'rJava', 'RWekajars', 'RTextTools', 'ggplot2', 'psych', 'dplyr', 'tidyr')
new.packages <- to.install[!(to.install %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
#This loads packages
lapply(to.install, require, character.only=T)
read.in<-NewsSource('/Users/Simon/Desktop/waterloo_articles.txt')
#Corpus
corp<-Corpus(read.in)
corp
class(corp)
#Examine
meta(corp[[1]])
#Extract Origins
sections<-lapply(corp, function(x) meta(x, 'section'))
sections<-unlist(sections)
sections<-table(sections)
#Store corp As A Backup
corp2<-corp
setwd('/Users/Simon/Dropbox/Fluoridation/Content Analysis')
dat<-read.csv('waterloo.content.analysis.csv', header=TRUE)
#Add In ProQuest Document ID
dat$id<-unlist(meta(corp, tag='id', type='local'))
#Delete Irrlelevant Articles
#Store irrelevant article numbers in Relevancy
dat$Relevancy<-ifelse(is.na(dat$Relevancy)==TRUE, 0, 1)
#Store Included stories in includes
includes<-dat[dat$Relevancy!=1,1]
#Delete irrelevant articles from corp
corp<-corp[includes]
#Delete from dat
dat<-dat[dat$Relevancy!=1,]
#Check the length of both are identical
length(corp)
nrow(dat)
#Attach Dates
corp[[1]]
story.dates<-lapply(corp, function(x) meta(x, "datetimestamp"))
dat$dates<-melt(story.dates)$value
dat$dates<-as.Date(dat$dates)
dat$date.weeks<-cut(dat$dates, 'weeks')
dat$date.months<-cut(dat$dates, 'months')
dat$date.quarters<-cut(dat$dates, '3 months')
#Add Author
authors<-lapply(corp, function(x) meta(x, "author"))
authors[unlist(lapply(authors, function(x) length(x)))<1]<-NA
dat$authors<-trim(unlist(authors))
#Sections
sections<-lapply(corp, function(x) meta(x, "section"))
sections[unlist(lapply(sections, length))<1]<-NA
dat$sections<-unlist(sections)
#Recodea Article.Type To Factor
dat$Article.Type<-recode(dat$Article.Type, "1='News'; 2='Editorial'; 3='Letter'", levels=c('News', 'Letter', 'Editorial'))
#Table Article Type
article_type<-table(dat$Article.Type)
#Write article.type
write.table(article_type, 'article.type.csv', sep=',', row.names=FALSE)
dat[,6:23]<-data.frame(lapply(dat[,6:23], function(x) recode(x, "NA=0")))
names(dat)
sources<-dat%>%
filter(Article.Type=='News')%>%
select(c(6:23,27))
names(sources)
sources.quote.table<-sources%>%
select(-starts_with('date'))%>%
gather(sources) %>%
separate(col=sources, into=c('source', 'tone')) %>%
group_by(source) %>%
rename(Source=source) %>%
summarise(n=sum(value))
#Recode scientist
sources.quote.table$Source<-recode(sources.quote.table$Source, as.factor.result=TRUE,"'Sci'='Scientist'", levels=c('Activist', 'Scientist', 'Politician', 'Citizen', 'Official', 'Other'))
#Write Sources
write.table(sources.quote.table, 'sources.quote.table.csv', sep=',', row.names=FALSE)
tone.quote.table<-sources %>%
select(-starts_with('date'))%>%
gather(sources)%>%
separate(col=sources, into=c('source', 'tone')) %>%
group_by(tone) %>%
summarise(n=sum(value))%>%
rename(Tone=tone)
tone.quote.table$Tone<-recode(tone.quote.table$Tone,"'against'='Against' ; 'for'='For' ; 'neutral'='Neutral'", levels=c('For', 'Neutral', 'Against') )
#Write quotation Tone
write.table(tone.quote.table, 'tone.quote.table.csv', sep=',', row.names=FALSE)
#Write Sources By tone
sources.tone.quote.table<-sources %>%
select(-starts_with('date'))%>%
gather(sources) %>%
separate(col=sources, into=c('source', 'tone')) %>%
group_by(source, tone) %>%
summarise(n=sum(value)) %>%
rename(Source=source, Tone=tone)
sources.tone.quote.table$Tone<-recode(sources.tone.quote.table$Tone, as.factor.result=TRUE,"'against'='Against' ; 'for'='For'; 'neutral'='Neutral'", levels=c('For', 'Neutral', 'Against'))
sources.tone.quote.table$Source<-recode(sources.tone.quote.table$Source, as.factor.result=TRUE,"'Sci'='Scientist'", levels=c('Activist', 'Scientist', 'Politician', 'Citizen', 'Official', 'Other'))
ggplot(sources.tone.quote.table, aes(x=Source, y=n, group=Source))+geom_bar(stat='identity')+facet_wrap(~Tone)+labs(x='Source', y='Frequency')+theme(axis.text.x = element_text(angle = 45, hjust = 1))
sources
sources%>%
gather(sources, value,-date.months)%>%
separate(col=sources, into=c('source', 'tone')) %>%
select(-source)%>%
group_by(tone, date.months)%>%
summarise(n=sum(value))%>%
spread(tone, n)%>%
mutate(Ratio=`for`-against)%>%
rename(Date=date.months) %>%
ggplot(aes(x=Date, y=Ratio))+geom_point()+ylim(-8,+8)+theme(axis.text.x = element_text(angle = 45, hjust = 1))
#Rename Tone Variable
dat$Tone<-recode(dat$Overall.Tone.Argument, as.factor.result=TRUE,"1='Pro-fluoridation'; 2='Neutral'; 3='Con-fluoridation'", levels=c('Pro-fluoridation', 'Neutral', 'Con-fluoridation'))
#Table Tone For descriptive purposes
tone_table<-table(dat$Tone)
#Join with article type
article_tone_table<-cbind(rownames(article_type),article_type, rownames(tone_table), tone_table)
#Write out article type and tone for descriptives
write.table(article_tone_table, file='article_tone_table.csv', row.names=FALSE, sep=',')
#Turn Date into date class
date.months<-as.Date(dat$date.months)
#Create Plot Of Article Tone By Article Type by Date
dat %>%
group_by(Article.Type, date.months, Tone) %>%
filter(Article.Type!='Editorial') %>%
summarize(value=sum(Tone))%>%
ggplot(aes(y=value, x=date.months))+geom_bar(stat='identity')+facet_grid(Article.Type~Tone)+labs(x='Date, by Months', y='Frequency', title='Fluoridation Articles By Type And Tone')+theme(axis.text.x = element_text(angle = 45, hjust = 1, size=6))
corp<-tm_map(corp, content_transformer(tolower))
corp<-tm_map(corp, removeWords, stopwords("english"))
corp<-tm_map(corp, content_transformer(removePunctuation))
corp<-tm_map(corp, content_transformer(function(x) gsub('hydrofluorosilicic acid', 'hydrofluoro', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('hydrofluosilicic acid', 'hydrofluoro', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('hydroflourosilic acid', 'hydrofluoro', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('hydroflourosilic acid', 'hydrofluoro', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('hydrofluorocilic acid', 'hydrofluoro', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('hydrofluorosilic acid', 'hydrofluoro', x)))
out<-DocumentTermMatrix(corp)
inspect(out)
corp<-tm_map(corp, content_transformer(function(x) gsub('hydrofluosilic acid', 'hydrofluoro', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('hfsa', 'hydrofluoro', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('not safe', 'notsafe', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('per cent', 'percent', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('unsafe', 'notsafe', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('not benefit', 'notbenefit', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('no benefits', 'notbenefit', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('benefit', 'benifici', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('low-income', 'lowincome', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('dry skin', 'dryskin', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('side effects', 'sideeffects', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('side-effects', 'sideeffects', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('not safe', 'notsafe', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('premature aging', 'prematureaging', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('bone weakening', 'boneweakening', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('precautionary', 'precaution', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('world health organization', 'whox', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('centers for disease control', 'cdcx', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('center for disease control', 'cdcx', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('centres for disease control', 'cdcx', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('centre for disease control', 'cdcx', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('canadian medical association', 'cma', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('health canada', 'healthcanada', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('chief dental officer', 'cdo', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('ontario dental association', 'oda', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('canadian dental association', 'cda', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('canadian pediatric society', 'cps', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('cost-effective', 'costeffective', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('cost effective', 'costeffective', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('chemicals', 'chemical', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('not effective', 'noteffective', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('limits cavities', 'xcavities', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('prevent cavities', 'xcavities', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('reduce cavities', 'xcavities', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('fight cavities', 'xcavities', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('no cavities', 'xcavities', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('fighting cavities', 'xcavities', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('fights cavities', 'xcavities', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('caries', 'xcavities', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('likelihood of cavities', 'xcavities', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('incidence of cavities', 'xcavities', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('dental health', 'dentalhealth', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('public health', 'publichealth', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('scare tactics', 'scaretactic', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('scare tactic', 'scaretactic', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('fear-mongering', 'fearmongering', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('fluoridation', 'fluorid', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('fluoride', 'fluorid', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('fluoridated', 'fluorid', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('fluoridating', 'fluorid', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('forced', 'force', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('medicate', 'xmedicate', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('medicating', 'xmedicate', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('scientific', 'science', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('scientist|scientists', 'science', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('fleming', 'xflem', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('vieth', 'xvieth', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('halloran', 'xhalloran', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('falla', 'xfalla', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('cooney', 'xcooney', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('kirshen', 'xkirshen', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub('nolan', 'xnolan', x)))
#Remove Stopwords
corp<-tm_map(corp, content_transformer(function(x) gsub('(http[^ ]*)', '', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub("(www[^ ]*)", '', x)))
corp<-tm_map(corp, content_transformer(function(x) gsub("[^ ]+therecordcom?", '', x)))
corp<-tm_map(corp, stemDocument, 'english')
control=list(weighting=weightTfIdf))
procedure<-c('referendum', 'plebiscit', 'turnout', 'debat', 'democrat', 'democraci',  'legisl','citizen')
# risks<-c('rash', 'sideeffect', 'fluorosi', 'radioact', 'notsaf', 'cancer', 'prematureag', 'thyroid','boneweaken', 'neurolog', 'thalidomid','fractur', 'osteoporosi', 'osteosarcoma', 'unsafe')
liberty<-c('forc',  'right', 'consent','xmedic')
risks<-c('toxic', 'chemic','hydrofluoro', 'cancer', 'fluorosi')
benefits<-c('dentalhealth', 'publichealth', 'benefici', 'safe','children', 'lowincom',  'caviti','xcaviti','costeffect', 'effect')
authority<-c('whox', 'cdcx', 'cma', 'cdo', 'cps', 'cda', 'oda')
lies<-c('misinform','scaretact', 'fearmong')
fluoride<-c('fluorid')
names(dat)
?FindFreqTerms
?findFreqTerms
tdm<-TermDocumentMatrix(corp, control=list(dictionary=x, weighting=weightTfIdf))
tdm<-TermDocumentMatrix(corp, control=list(weighting=weightTfIdf))
findFreqTerms(tdm, lowfreq=nrow(dat)/4, highfreq=nrow(dat))
findFreqTerms(tdm)
findFreqTerms(tdm, lowfreq=1)
findFreqTerms(tdm, lowfreq=2)
head(tdm)
inspect(tdm)
summary(tdm)
summary(inspect(tdm))
inspecxt(tdm)
inspect(tdm)
findFreqTerms(tdm, lowfreq=0.5,highfreq=5)
findFreqTerms(tdm, lowfreq=0.2,highfreq=5)
findFreqTerms(tdm, lowfreq=0.2,highfreq=4)
findFreqTerms(tdm, lowfreq=0.2,highfreq=3)
findFreqTerms(tdm, lowfreq=0.2,highfreq=2)
findFreqTerms(tdm, lowfreq=0.2,highfreq=1)
findFreqTerms(tdm, lowfreq=0.1,highfreq=1)
findFreqTerms(tdm, lowfreq=0.3,highfreq=1)
test<-findFreqTerms(tdm, lowfreq=0.3,highfreq=1)
tdm[,test]
tdm[test]
inspect(tdm[test])
inspect(tdm)[test]
tdm<-TermDocumentMatrix(corp)
test<-findFreqTerms(tdm, lowfreq=1)
inspect(test)
inspect(test)
test
test<-findFreqTerms(tdm, lowfreq=2)
test
test<-findFreqTerms(tdm, lowfreq=3)
test
test<-findFreqTerms(tdm, lowfreq=nrow(dat)/4)
test
test<-findFreqTerms(tdm, lowfreq=nrow(dat)/5)
test
tdm[,'acid']
inspect(tdm[,'acid'])
inspect(tdm[,acid])
inspect(tdm)
inspect(tdm)[,acid]
inspect(tdm)[acid]
tdm['acid',]
tdm['hydrofluoro',]
tdm[test,]
inspect(tdm[test,])
test<-findFreqTerms(tdm, lowfreq=nrow(dat)/6, highfreq=nrow(dat))
inspect(tdm[test,])
test
test<-findFreqTerms(tdm, lowfreq=nrow(dat)/6, highfreq=nrow(dat)/2)
inspect(tdm[test,])
test
test<-findFreqTerms(tdm, lowfreq=nrow(dat)/6, highfreq=nrow(dat))
?hclust
hclust(test)
tdm.freq<-findFreqTerms(tdm, lowfreq=nrow(dat)/6, highfreq=nrow(dat))
TermDocumentMatrix(corp, control=list(dicdtionary=tdm.freq))
TermDocumentMatrix(corp, control=list(dictionary=tdm.freq))
tdm[tdm.freq,]
tdm.out<-tdm[tdm.freq,]
tdm.out<-as.matrix(tdm.out)
dist(tdm.out)
fit<-dist(tdm.out)
hclust(fit)
plot(hclust(fit))
tdm.freq<-findFreqTerms(tdm, lowfreq=nrow(dat)/6, highfreq=50))
tdm.freq<-findFreqTerms(tdm, lowfreq=nrow(dat)/6, highfreq=98)
tdm.out<-tdm[tdm.freq,]
tdm.out
inspect(tdm.out)
tdm.freq
stemDocument('candidate')
stemDocument('candidates')
c('1967', '2010', 'add' , 'ago', 'agre', 'allow', 'also', 'amount', 'angela', 'anoth', 'area', 'ask', 'associ', 'becom', 'believ', 'best', 'call', 'cabirdg', 'canada', 'canadian', 'care', 'caus', 'centr', 'chang', 'claim', 'clear', 'come', 'committe', 'communiti', 'concern', 'contain', 'control',  'credit','critic', 'current','dailli', 'day', 'decis', 'develop', 'differ', 'done', 'eat', 'elect', 'elmira', 'end', 'endors', 'even', 'evri', 'fals', 'favour', 'first','follow', 'food', 'found', 'four', 'get', 'held', 'includ', 'increas', 'inform', 'issu', 'jacob', 'just', 'keep', 'kitchen', 'last', 'lead', 'level', 'liana', 'liber', 'like', 'live', 'long', 'look', 'lot', 'make', 'mani', 'may', 'measur', 'meet', 'merger', 'million', 'month','much', 'must', 'need', 'new', 'next', 'now', 'number', 'oct', 'ontario', 'part', 'per', 'plan', 'point', 'put', 'rate', 'recommend', 'record', 'report', 'result', 'right', '', 'robert', 'ross', 'say', 'school', 'see', 'servic', 'show', 'side', 'sinc', 'staff', 'state', 'stop', 'street','sugar', 'suggest', 'suppli', 'support', 'system', 'take', 'talk','think','three', 'time', 'told', 'toronto', 'transit', 'true', 'two', 'univers', 'use', 'want', 'way', 'week', 'well', 'whether', 'without', 'year', 'yes')
sub.out<-c('1967', '2010', 'add' , 'ago', 'agre', 'allow', 'also', 'amount', 'angela', 'anoth', 'area', 'ask', 'associ', 'becom', 'believ', 'best', 'call', 'cabirdg', 'canada', 'canadian', 'care', 'caus', 'centr', 'chang', 'claim', 'clear', 'come', 'committe', 'communiti', 'concern', 'contain', 'control',  'credit','critic', 'current','dailli', 'day', 'decis', 'develop', 'differ', 'done', 'eat', 'elect', 'elmira', 'end', 'endors', 'even', 'evri', 'fals', 'favour', 'first','follow', 'food', 'found', 'four', 'get', 'held', 'includ', 'increas', 'inform', 'issu', 'jacob', 'just', 'keep', 'kitchen', 'last', 'lead', 'level', 'liana', 'liber', 'like', 'live', 'long', 'look', 'lot', 'make', 'mani', 'may', 'measur', 'meet', 'merger', 'million', 'month','much', 'must', 'need', 'new', 'next', 'now', 'number', 'oct', 'ontario', 'part', 'per', 'plan', 'point', 'put', 'rate', 'recommend', 'record', 'report', 'result', 'right', '', 'robert', 'ross', 'say', 'school', 'see', 'servic', 'show', 'side', 'sinc', 'staff', 'state', 'stop', 'street','sugar', 'suggest', 'suppli', 'support', 'system', 'take', 'talk','think','three', 'time', 'told', 'toronto', 'transit', 'true', 'two', 'univers', 'use', 'want', 'way', 'week', 'well', 'whether', 'without', 'year', 'yes')
tdm.out %in% sub.out
tdm.freq %in% sub.out
tdm.freq[tdm.freq %in% sub.out]
tdm.freq[-tdm.freq %in% sub.out]
tdm.freq[!tdm.freq %in% sub.out]
tdm.freq<-tdm.freq[!tdm.freq %in% sub.out]
tdm.out<-tdm[tdm.freq,]
tdm.out<-as.matrix(tdm.out)
fit<-dist(tdm.out)
plot(hclust(fit))
sub.out<-c('1967', '2010', 'add' , 'ago', 'agre', 'allow', 'also', 'amount', 'angela', 'anoth', 'area', 'ask', 'associ', 'becom', 'believ', 'best', 'call', 'cambridg', 'canada', 'canadian', 'care', 'caus', 'centr', 'chang', 'claim', 'clear', 'come', 'committe', 'communiti', 'concern', 'contain', 'control',  'credit','critic', 'current','dailli', 'day', 'decis', 'develop', 'differ', 'done', 'eat', 'elect', 'elmira', 'end', 'endors', 'even', 'evri', 'fals', 'favour', 'first','follow', 'food', 'found', 'four', 'get', 'held', 'includ', 'increas', 'inform', 'issu', 'jacob', 'just', 'keep', 'kitchen', 'last', 'lead', 'level', 'liana', 'liber', 'like', 'live', 'long', 'look', 'lot', 'make', 'mani', 'may', 'measur', 'meet', 'merger', 'million', 'month','much', 'must', 'need', 'new', 'next', 'now', 'number', 'oct', 'ontario', 'part', 'per', 'plan', 'point', 'put', 'rate', 'recommend', 'record', 'report', 'result', 'right', '', 'robert', 'ross', 'say', 'school', 'see', 'servic', 'show', 'side', 'sinc', 'staff', 'state', 'stop', 'street','sugar', 'suggest', 'suppli', 'support', 'system', 'take', 'talk','think','three', 'time', 'told', 'toronto', 'transit', 'true', 'two', 'univers', 'use', 'want', 'way', 'week', 'well', 'whether', 'without', 'year', 'yes')
tdm<-TermDocumentMatrix(corp)
tdm<-TermDocumentMatrix(corp)
tdm.freq<-findFreqTerms(tdm, lowfreq=nrow(dat)/3, highfreq=98)
tdm<-TermDocumentMatrix(corp)
tdm.freq<-findFreqTerms(tdm, lowfreq=nrow(dat)/3, highfreq=nrow(dat)/2)
tdm<-TermDocumentMatrix(corp)
tdm.freq<-findFreqTerms(tdm, lowfreq=nrow(dat)/6, highfreq=nrow(dat)/2)
tdm.freq
tdm<-TermDocumentMatrix(corp)
tdm.freq<-findFreqTerms(tdm, lowfreq=nrow(dat)/10, highfreq=nrow(dat)/2)
tdm.freq
tdm<-TermDocumentMatrix(corp)
tdm.freq<-findFreqTerms(tdm, lowfreq=nrow(dat)/3, highfreq=nrow(dat)/2)
tdm.freq
tdm.freq
tdm[tdm.freq]
tdm[tdm.freq,]
removeSparseTerms(0.8)
removeSparseTerms(tdm,0.8)
removeSparseTerms(tdm[tdm.freq,],0.8)
inspect(removeSparseTerms(tdm[tdm.freq,],0.8))
98/5
tdm.freq<-findFreqTerms(tdm, lowfreq=nrow(dat)/5, highfreq=nrow(dat)/2)
tdm.freq
tdm.freq<-findFreqTerms(tdm, lowfreq=nrow(dat)/10, highfreq=nrow(dat)/2)
tdm.freq
tdm.freq<-findFreqTerms(tdm, lowfreq=nrow(dat)/6, highfreq=nrow(dat)/2)
tdm.freq
sub.out<-c('1967', '2010', 'add' , 'ago', 'agre', 'allow', 'also', 'amount', 'angela', 'anoth', 'area', 'ask', 'associ', 'becom', 'believ', 'best', 'call', 'cambridg', 'canada', 'canadian', 'care', 'caus', 'centr', 'chang', 'claim', 'clear', 'come', 'committe', 'communiti', 'concern', 'contain', 'control',  'credit','critic', 'current','dailli', 'day', 'decis', 'develop', 'differ', 'done', 'eat', 'elect', 'elmira', 'end', 'endors', 'even', 'evri', 'fals', 'favour', 'first','follow', 'food', 'found', 'four', 'get', 'held', 'includ', 'increas', 'inform', 'issu', 'jacob', 'just', 'keep', 'kitchen', 'last', 'lead', 'level', 'liana', 'liber', 'like', 'live', 'long', 'look', 'lot', 'make', 'mani', 'may', 'measur', 'meet', 'merger', 'million', 'month','much', 'must', 'need', 'new', 'next', 'now', 'number', 'oct', 'ontario', 'part', 'per', 'plan', 'point', 'put', 'rate', 'recommend', 'record', 'report', 'result', 'right', '', 'robert', 'ross', 'say', 'school', 'see', 'servic', 'show', 'side', 'sinc', 'staff', 'state', 'stop', 'street','sugar', 'suggest', 'suppli', 'support', 'system', 'take', 'talk','think','three', 'time', 'told', 'toronto', 'transit', 'true', 'two', 'univers', 'use', 'want', 'way', 'week', 'well', 'whether', 'without', 'year', 'yes')
tdm.freq<-tdm.freq[!tdm.freq %in% sub.out]
tdm.out<-tdm[tdm.freq,]
tdm.out<-as.matrix(tdm.out)
fit<-dist(tdm.out)
plot(hclust(fit))
?rect.hclust
rect.hclust(fit,  h=10)
plot(hclust(fit))
rect.hclust(fit,  h=10)
plot(rect.hclust(fit,  h=10))
x<-hclust(fit)
rect.hclust(x,  h=10)
x<-hclust(fit)
fit<-dist(tdm.out)
x<-hclust(fit)
rect.hclust(x,  h=15)
fit<-dist(tdm.out)
x<-hclust(fit)
rect.hclust(x,  h=15)
plot(x)
rect.hclust(x,  h=15)
x
names(x)
subset(x, height<15)
x$height
subset(x, height<15)
?ggdendo
?ggdendogram
library(ggplot2)
library(ggdendro)
install.packages('ggdendro')
install.packages("knitr")
?require
?install.packages
install.packages('plotrix')
options('repos')
source_url<-'https://github.com/sjkiss/LSIRM/blob/master/package_install.R''
source_url<-'https://github.com/sjkiss/LSIRM/blob/master/package_install.R'
library(devtools)
install.packages('devtools')
library(devtools)
source_url<-'https://github.com/sjkiss/LSIRM/blob/master/package_install.R'
library(devtools)
source_url
Sys.setenv(NOAWT=TRUE)
to.install<-c('tm', 'car', 'tm.plugin.waterloo', 'SnowballC', 'RWeka', 'rJava', 'RWekajars', 'RTextTools', 'ggplot2', 'psych', 'dplyr', 'tidyr')
new.packages <- to.install[!(to.install %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(to.install, require, character.only=T)
read.in<-NewsSource('/Users/Simon/Desktop/waterloo_articles.txt')
corp<-Corpus(read.in)
corp
class(corp)
meta(corp[[1]])
code_url<-'https://github.com/sjkiss/LSIRM/blob/master/package_install.R'
library(devtools)
source_url(code_url)
library(devtools)
code_url<-'https://github.com/sjkiss/LSIRM/blob/master/package_install.R'
source_url(code_url)
source(code_url)
source_url(code_url)
code_url<-'https://github.com/sjkiss/LSIRM/blob/master/package_install.R'
source_url(code_url)
SourceURL <- "https://raw.github.com/christophergandrud/christophergandrud.github.com/master/SourceCode/CarsScatterExample.R"
source_url(SourceURL)
code_url<-'https://github.com/sjkiss/LSIRM/blob/master/package_install.R'
source(code_url)
install_github("leeper/rio")
library("rio")
import(code_url)
code_url
import('https://github.com/sjkiss/LSIRM/blob/master/package_install.R')
source_https <- function(url, ...) {
# load package
require(RCurl)
# parse and evaluate each .R script
sapply(c(url, ...), function(u) {
eval(parse(text = getURL(u, followlocation = TRUE, cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))), envir = .GlobalEnv)
})
}
code_url<-'https://raw.githubusercontent.com/sjkiss/LSIRM/master/package_install.R'
source_url(code_url)
source_url(code_url)
source_url(code_url)
?install.packages
get.option('verbose')
getOption('verbose')
source_url(code_url)
library(nnet)
library(psy)
library(epitools)
source_url(code_url)
code_url<-'https://raw.githubusercontent.com/sjkiss/LSIRM/master/package_install.R'
source_url(code_url)
code_url<-'https://raw.githubusercontent.com/sjkiss/LSIRM/master/package_install.R'
source_url(code_url)
code_url<-'https://raw.githubusercontent.com/sjkiss/LSIRM/master/package_install.R'
source_url(code_url)
library(epitools)
open(.Rprofile)
source_url(code_url)
code_url<-'https://raw.githubusercontent.com/sjkiss/LSIRM/master/package_install.R'
source_url(code_url)
code_url<-'https://raw.githubusercontent.com/sjkiss/LSIRM/master/package_install.R'
source_url(code_url)
source_url(code_url)
source_url(code_url)
print('Congratulations, it looks like the necessary packages have been installed. If everything has worked correctly, a test plot should appear in the RStudio screen called `Test Plot''')
#Test Command
print('Congratulations, it looks like the necessary packages have been installed.
print('Congratulations, it looks like the necessary packages have been installed.
If everything has worked correctly, a test plot should appear in the RStudio screen called `Test Plot'')
print('Congratulations, it looks like the necessary packages have been installed.
If everything has worked correctly, a test plot should appear in the RStudio screen called `Test Plot'')
print('Congratulations, it looks like the necessary packages have been installed. If everything has worked correctly, a test plot should appear in the RStudio screen called `Test Plot'')
print('Congratulations, it looks like the necessary packages have been installed. If everything has worked correctly, a test plot should appear in the RStudio screen called `Test Plot\'')
print('Congratulations, it looks like the necessary packages have been installed. If everything has worked correctly, a test plot should appear in the RStudio screen called `Test Plot\'')
print('Congratulations, it looks like the necessary packages have been installed. If everything has worked correctly, a test plot should appear in the RStudio screen called \'Test Plot\'')
print('Congratulations, it looks like the necessary packages have been installed. If everything has worked correctly, a test plot should appear in the RStudio screen called \'Test Plot\'. If not, please contact Simon Kiss at skiss@wlu.ca')
source_url(code_url)
source_url(code_url)
source_url(code_url)
Sys.setenv(NOAWT=TRUE)
to.install<-c('tm', 'car', 'tm.plugin.waterloo', 'SnowballC', 'RWeka', 'rJava', 'RWekajars', 'RTextTools', 'ggplot2', 'psych', 'dplyr', 'tidyr', 'reshape2', 'scales')
new.packages <- to.install[!(to.install %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
#This loads packages
lapply(to.install, require, character.only=T)
read.in<-NewsSource('/Users/Simon/Desktop/waterloo_articles.txt')
Sys.setenv(NOAWT=TRUE)
to.install<-c('tm', 'car', 'tm.plugin.waterloo', 'SnowballC', 'RWeka', 'rJava', 'RWekajars', 'RTextTools', 'ggplot2', 'psych', 'dplyr', 'tidyr', 'reshape2', 'scales')
new.packages <- to.install[!(to.install %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
